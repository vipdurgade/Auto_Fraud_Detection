# ğŸš¨ Car Insurance Fraud Detection Using Machine Learning

## ğŸ“Œ Project Overview

Insurance fraud is a major challenge for insurance companies, costing billions of dollars annually. The goal of this project is to build a robust machine learning model that can automatically detect fraudulent insurance claims with high accuracy. Early detection not only helps insurers save money but also ensures honest claimants are served faster.

---

## ğŸ¯ Objectives

* Identify key patterns and indicators of fraud in insurance claims
* Clean and transform raw claim data for effective model training
* Train and evaluate various machine learning models to classify claims as **fraudulent** or **legitimate**
* Determine the most important features contributing to fraud detection
* Develop a deployable pipeline that can be integrated into real-world systems

---
Dataset
In this study, we have used Kaggle provided dataset of Auto Insurance Claim contains 1000 rows and 40 columns shape.

Column Name	Describe
Policy_annual_premium	Amount of insured need to pay over the year
Insured_zip	Insured number
Capital-gains	Profit on earns of the sales
Capital-loss	Loss incurred
Incident_hour of the day	Hour of the day incident occurred
Total claim amount	Total Amount of claims
Injury claim	Amount of injury claims
Property claim	Amount of property claim
Vehicle claim	Amount of vehicle claim
Policy_state	State of policy holder
Policy_csl	Combined single limit of policy
Policy_deductable	Amount of first pay
Insured_sex	Gender
Insured_hobbies	Hobby of insured
Incident_type	Type of incident occurred
Collision_type	Type of damaged parts
Incident_severity	Type of severity damaged
Authorities contacted	Type of authorities has contacted on incident
Incident_state	State of incident
Incident_city	City of incident
Number of vehicle	Number of vehicle involved
Property damaged	Property damaged or not
Bodily injuries	Number of bodily injured
Witnesses	Number of witnesses
Auto_year	Year of auto model
Police_report	Available or not
Auto_make	Fabrication of Auto
Auto_model	Auto model
(back to top)

Data Preparation
Dataset
In this study, we have used Kaggle provided dataset of Auto Insurance Claim contains 1000 rows and 40 columns shape.

Column Name	Describe
Policy_annual_premium	Amount of insured need to pay over the year
Insured_zip	Insured number
Capital-gains	Profit on earns of the sales
Capital-loss	Loss incurred
Incident_hour of the day	Hour of the day incident occurred
Total claim amount	Total Amount of claims
Injury claim	Amount of injury claims
Property claim	Amount of property claim
Vehicle claim	Amount of vehicle claim
Policy_state	State of policy holder
Policy_csl	Combined single limit of policy
Policy_deductable	Amount of first pay
Insured_sex	Gender
Insured_hobbies	Hobby of insured
Incident_type	Type of incident occurred
Collision_type	Type of damaged parts
Incident_severity	Type of severity damaged
Authorities contacted	Type of authorities has contacted on incident
Incident_state	State of incident
Incident_city	City of incident
Number of vehicle	Number of vehicle involved
Property damaged	Property damaged or not
Bodily injuries	Number of bodily injured
Witnesses	Number of witnesses
Auto_year	Year of auto model
Police_report	Available or not
Auto_make	Fabrication of Auto
Auto_model	Auto model



## ğŸ“‚ Workflow & Steps Followed

### 1. ğŸ§¹ Data Cleaning

* Handled missing values (e.g., in `collision_type`, `property_damage`, and `police_report_available`)
* Replaced unknown entries (`?`) with `NaN` and filled using mode imputation
* Dropped irrelevant date columns
* Extracted useful information (e.g., pin code and street from address)
* Encoded categorical variables using `factorize` and mapping techniques

### 2. ğŸ“Š Exploratory Data Analysis (EDA)

* Visualized missing data using `missingno`
* Checked data distribution, class balance, and unique values in categorical columns
* Examined correlations and patterns among variables

### 3. ğŸ”„ Data Transformation

* Combined cleaned categorical and numerical data into a single feature set
* Ensured all features were numerical and ready for modeling
* Split the dataset into **training** and **testing** sets using `train_test_split`

### 4. ğŸ¤– Model Building & Evaluation

Several models were experimented with, including:

* **XGBoost Classifier**: Final model used
* Evaluated performance using `.score()` on training and test sets
* Visualized **feature importance** to understand model decisions

---

## âœ… Final Results

| Metric                | Value  |
| --------------------- | ------ |
| **Training Accuracy** | 0.9643 |
| **Testing Accuracy**  | 0.9393 |

* The XGBoost model achieved **93.9% accuracy** on unseen test data
* Important fraud indicators included:

  * `incident_severity`
  * `insured_occupation`
  * `total_claim_amount`
  * `collision_type`
  * `policy_csl`

---

## ğŸ§° Tech Stack

* **Python** (pandas, numpy, matplotlib, seaborn, missingno)
* **Scikit-learn** (for preprocessing)
* **XGBoost** (final model)
* **Joblib** (for model serialization)
* **Streamlit** (for app deployment)

---

## ğŸš€ How to Run

```bash
# Clone the repository
git clone https://github.com/your-username/insurance-fraud-detection.git
cd insurance-fraud-detection

# Install dependencies
pip install -r requirements.txt

# Run the Streamlit app
streamlit run app.py
```

---

## ğŸ“ Conclusion

This project demonstrates a complete pipeline from data wrangling to machine learning modeling, offering insights into fraud detection in the insurance industry. The final model is accurate, interpretable, and ready for deployment.


